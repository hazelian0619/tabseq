{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TabSeq-Trace: 框架设计\n",
                "\n",
                "本 Notebook 实现了 **TabSeq-Trace** 框架的核心组件。\n",
                "\n",
                "## 1. 方法论概述 (Methodology Overview)\n",
                "核心理念是将**回归任务 (Regression)** 重构为**二叉树上的序列生成任务**。\n",
                "- **因果序列建模 (Autoregressive Modeling)**: 模型输入为历史轨迹 `[SOS, b_1, b_2, ...]`，输出为当前步的多热分布预测。\n",
                "- **全息推理 (Holographic Inference)**: 基于 Multi-hot 的软约束累乘，重构概率密度。\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.datasets import fetch_california_housing\n",
                "from typing import List, Tuple, Dict, Optional\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 轨迹标签编码器 (Trace Label Encoder)\n",
                "将连续标签映射为二进制决策序列。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TraceLabelEncoder:\n",
                "    def __init__(self, v_min: float, v_max: float, depth: int = 10):\n",
                "        self.v_min = v_min\n",
                "        self.v_max = v_max\n",
                "        self.depth = depth\n",
                "        self.n_bins = 2 ** depth \n",
                "        self.bin_width = (v_max - v_min) / self.n_bins\n",
                "\n",
                "    def encode(self, y: float) -> Tuple[List[int], int]:\n",
                "        y = np.clip(y, self.v_min, self.v_max)\n",
                "        norm_y = (y - self.v_min) / (self.v_max - self.v_min)\n",
                "        leaf_idx = int(min(np.floor(norm_y * self.n_bins), self.n_bins - 1))\n",
                "        binary_str = format(leaf_idx, f'0{self.depth}b')\n",
                "        sequence = [int(bit) for bit in binary_str]\n",
                "        return sequence, leaf_idx\n",
                "    \n",
                "    def encode_multi_hot(self, leaf_idx: int) -> np.ndarray:\n",
                "        multi_hot = np.zeros((self.depth, self.n_bins), dtype=np.float32)\n",
                "        start, end = 0, self.n_bins\n",
                "        for t in range(self.depth):\n",
                "            mid = (start + end) // 2\n",
                "            if leaf_idx < mid:\n",
                "                multi_hot[t, start:mid] = 1.0\n",
                "                end = mid\n",
                "            else:\n",
                "                multi_hot[t, mid:end] = 1.0\n",
                "                start = mid\n",
                "        return multi_hot\n",
                "\n",
                "    def decode_bin_index(self, bin_idx: int) -> float:\n",
                "        return self.v_min + (bin_idx + 0.5) * self.bin_width\n",
                "\n",
                "    def decode_sequence(self, sequence: List[int]) -> float:\n",
                "        bin_idx = 0\n",
                "        for bit in sequence:\n",
                "            bin_idx = (bin_idx << 1) | bit\n",
                "        return self.decode_bin_index(bin_idx)\n",
                "\n",
                "    def get_bin_edges(self, bin_idx: int) -> Tuple[float, float]:\n",
                "        lower = self.v_min + bin_idx * self.bin_width\n",
                "        upper = lower + self.bin_width\n",
                "        return lower, upper"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. TabSeq 数据集加载器 (TabSeq Dataset Loader)\n",
                "**自回归架构**：Input: `[SOS, b1...]`, Target: `[MHT_0, MHT_1...]`。\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TabSeqDataset(Dataset):\n",
                "    def __init__(self, \n",
                "                 X_num: np.ndarray, \n",
                "                 X_cat: np.ndarray, \n",
                "                 y: np.ndarray, \n",
                "                 encoder: TraceLabelEncoder,\n",
                "                 is_train: bool = True,\n",
                "                 sos_token: int = 2): \n",
                "        self.X_num = torch.FloatTensor(X_num) if X_num is not None else torch.empty(len(y), 0)\n",
                "        self.X_cat = torch.LongTensor(X_cat) if X_cat is not None else torch.empty(len(y), 0, dtype=torch.long)\n",
                "        self.y = torch.FloatTensor(y).view(-1)\n",
                "        self.encoder = encoder\n",
                "        self.is_train = is_train\n",
                "        self.sos_token = sos_token\n",
                "\n",
                "        self.y_seqs = []\n",
                "        self.y_multi_hots = []\n",
                "        \n",
                "        for val in y:\n",
                "            seq, leaf_idx = self.encoder.encode(val)\n",
                "            mht = self.encoder.encode_multi_hot(leaf_idx)\n",
                "            self.y_seqs.append(seq)\n",
                "            self.y_multi_hots.append(mht)\n",
                "            \n",
                "        self.y_seqs = torch.LongTensor(self.y_seqs)\n",
                "        self.y_multi_hots = torch.FloatTensor(self.y_multi_hots)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.y)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        x_n = self.X_num[idx]\n",
                "        x_c = self.X_cat[idx]\n",
                "        target_seq = self.y_seqs[idx]\n",
                "        \n",
                "        dec_input = torch.cat([\n",
                "            torch.tensor([self.sos_token], dtype=torch.long),\n",
                "            target_seq[:-1]\n",
                "        ])\n",
                "        \n",
                "        y_mht = self.y_multi_hots[idx]\n",
                "        y_raw = self.y[idx]\n",
                "        \n",
                "        return {\n",
                "            'x_num': x_n,\n",
                "            'x_cat': x_c,\n",
                "            'dec_input': dec_input,\n",
                "            'y_seq': target_seq,  \n",
                "            'y_mht': y_mht,\n",
                "            'y_raw': y_raw\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 测试"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_california_housing_loaders(batch_size: int = 64, \n",
                "                                   depth: int = 10, \n",
                "                                   val_split: float = 0.2):\n",
                "    data = fetch_california_housing()\n",
                "    X = data.data\n",
                "    y = data.target\n",
                "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_split, random_state=42)\n",
                "    \n",
                "    scaler = StandardScaler()\n",
                "    X_train_num = scaler.fit_transform(X_train)\n",
                "    X_val_num = scaler.transform(X_val)\n",
                "    \n",
                "    v_min, v_max = y.min() - 0.1, y.max() + 0.1\n",
                "    encoder = TraceLabelEncoder(v_min, v_max, depth)\n",
                "    \n",
                "    train_set = TabSeqDataset(X_train_num, None, y_train, encoder, is_train=True)\n",
                "    val_set = TabSeqDataset(X_val_num, None, y_val, encoder, is_train=False)\n",
                "    \n",
                "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
                "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
                "    \n",
                "    print(f\"数据集加载完毕: Depth={depth}\")\n",
                "    return train_loader, val_loader, encoder"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 全息评估指标 (Extended Holographic Metrics)\n",
                "\n",
                "**更新**: 与 Benchmark 逻辑完全对齐的评估指标。\n",
                "1. **预测区间命中率**: 全局覆盖率。\n",
                "2. **不同宽度区间命中率**: 按固定宽度分段。\n",
                "3. **分桶回归命中率**: 按 0.2 和 0.4 宽度分桶的分类准确率。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ExtendedHolographicMetric:\n",
                "    def __init__(self, encoder: TraceLabelEncoder):\n",
                "        self.encoder = encoder\n",
                "        # 定义分桶 (0.2 和 0.4)\n",
                "        self.bin_edges_02 = np.arange(0, 5.21, 0.2)\n",
                "        self.bin_edges_04 = np.arange(0, 5.21, 0.4)\n",
                "\n",
                "    def compute_metrics(self, \n",
                "                        model_probs: torch.Tensor, \n",
                "                        y_true: torch.Tensor, \n",
                "                        confidence: float = 0.90) -> Dict:\n",
                "        \"\"\"\n",
                "        计算全息评估指标，包括全局覆盖率、分段覆盖率和分桶回归命中率。\n",
                "        \"\"\"\n",
                "        batch_size, depth, n_bins = model_probs.shape\n",
                "        \n",
                "        # 1. 计算联合概率 & 归一化\n",
                "        # 逻辑：叶子 i 在所有 t 步都被预测为 True 的概率连乘\n",
                "        leaf_unnorm_probs = torch.prod(model_probs, dim=1)\n",
                "        leaf_probs = leaf_unnorm_probs / (torch.sum(leaf_unnorm_probs, dim=1, keepdim=True) + 1e-9)\n",
                "        \n",
                "        # 2. 构建 CDF\n",
                "        cdf = torch.cumsum(leaf_probs, dim=1)\n",
                "        \n",
                "        # 3. 点估计 (期望值)\n",
                "        bin_values = torch.tensor([self.encoder.decode_bin_index(i) for i in range(n_bins)], device=y_true.device)\n",
                "        y_pred_point = torch.sum(leaf_probs * bin_values, dim=1)\n",
                "        mae = torch.mean(torch.abs(y_pred_point - y_true)).item()\n",
                "        rmse = torch.sqrt(torch.mean((y_pred_point - y_true)**2)).item()\n",
                "        \n",
                "        # 4. 区间估计 (Extract Interval [L, U] from CDF)\n",
                "        alpha = 1.0 - confidence\n",
                "        lower_q = alpha / 2.0\n",
                "        upper_q = 1.0 - (alpha / 2.0)\n",
                "        \n",
                "        lower_indices = torch.argmax((cdf >= lower_q).int(), dim=1)\n",
                "        upper_indices = torch.argmax((cdf >= upper_q).int(), dim=1)\n",
                "        \n",
                "        L_pred = bin_values[lower_indices]\n",
                "        U_pred = bin_values[upper_indices]\n",
                "        \n",
                "        # --- 统一指标计算逻辑 ---\n",
                "        y_true_np = y_true.detach().cpu().numpy()\n",
                "        L_pred_np = L_pred.detach().cpu().numpy()\n",
                "        U_pred_np = U_pred.detach().cpu().numpy()\n",
                "        y_pred_point_np = y_pred_point.detach().cpu().numpy()\n",
                "        \n",
                "        covered = (y_true_np >= L_pred_np) & (y_true_np <= U_pred_np)\n",
                "        global_picp = np.mean(covered)\n",
                "        widths = U_pred_np - L_pred_np\n",
                "        mpiw = np.mean(widths)\n",
                "        \n",
                "        # A. 不同宽度区间命中率 (Stratified by Width)\n",
                "        fixed_bins = [0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 100.0]\n",
                "        bin_indices = np.digitize(widths, fixed_bins) - 1\n",
                "        \n",
                "        stratified_w = {}\n",
                "        for i in range(len(fixed_bins)-1):\n",
                "            mask = (bin_indices == i)\n",
                "            count = np.sum(mask)\n",
                "            if count > 0:\n",
                "                local_cov = np.mean(covered[mask])\n",
                "                range_str = f\"Width [{fixed_bins[i]:.1f}, {fixed_bins[i+1]:.1f})\"\n",
                "                stratified_w[range_str] = f\"{local_cov:.4f} (n={count})\"\n",
                "        \n",
                "        # B. 分桶回归命中率 (0.2 & 0.4)\n",
                "        true_bins_02 = np.digitize(y_true_np, self.bin_edges_02)\n",
                "        pred_bins_02 = np.digitize(y_pred_point_np, self.bin_edges_02)\n",
                "        bin_acc_02 = np.mean(true_bins_02 == pred_bins_02)\n",
                "\n",
                "        true_bins_04 = np.digitize(y_true_np, self.bin_edges_04)\n",
                "        pred_bins_04 = np.digitize(y_pred_point_np, self.bin_edges_04)\n",
                "        bin_acc_04 = np.mean(true_bins_04 == pred_bins_04)\n",
                "\n",
                "        return {\n",
                "            'MAE': mae,\n",
                "            'RMSE': rmse,\n",
                "            '预测区间命中率': global_picp,\n",
                "            'MPIW': mpiw,\n",
                "            '不同宽度区间命中率': stratified_w,\n",
                "            '分桶回归命中率_0.2': bin_acc_02,\n",
                "            '分桶回归命中率_0.4': bin_acc_04\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 功能验证 (Verification)\n",
                "验证 ExtendedHolographicMetric 是否正常工作。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "数据集加载完毕: Depth=6\n",
                        "\n",
                        "=== 基于 Multi-hot 输出的直接评估结果 (Extended) ===\n",
                        "MAE: 0.0234\n",
                        "分桶回归命中率 (0.2): 0.6250\n",
                        "分桶回归命中率 (0.4): 0.8750\n",
                        "预测区间命中率: 0.3750\n",
                        "不同宽度区间命中率:\n",
                        "  Width [0.0, 0.4): 0.3750 (n=8)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/vq/63m75vp55w1csm6kr6z12knc0000gn/T/ipykernel_70516/216803391.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
                        "  self.y_multi_hots = torch.FloatTensor(self.y_multi_hots)\n"
                    ]
                }
            ],
            "source": [
                "# 1. 准备数据\n",
                "train_loader, val_loader, encoder = get_california_housing_loaders(batch_size=8, depth=6)\n",
                "metric_calc = ExtendedHolographicMetric(encoder)\n",
                "\n",
                "# 2. Mock Model\n",
                "batch = next(iter(train_loader))\n",
                "B, D, N = 8, 6, 64\n",
                "mock_model_output = torch.where(batch['y_mht'] > 0.5, torch.tensor(0.9), torch.tensor(0.1))\n",
                "mock_model_output += torch.randn_like(mock_model_output) * 0.05\n",
                "mock_probs = torch.clamp(mock_model_output, 0.01, 0.99)\n",
                "\n",
                "# 运行评估\n",
                "metrics = metric_calc.compute_metrics(mock_probs, batch['y_raw'], confidence=0.90)\n",
                "print(\"\\n=== 基于 Multi-hot 输出的直接评估结果 (Extended) ===\")\n",
                "print(f\"MAE: {metrics['MAE']:.4f}\")\n",
                "print(f\"分桶回归命中率 (0.2): {metrics['分桶回归命中率_0.2']:.4f}\")\n",
                "print(f\"分桶回归命中率 (0.4): {metrics['分桶回归命中率_0.4']:.4f}\")\n",
                "print(f\"预测区间命中率: {metrics['预测区间命中率']:.4f}\")\n",
                "print(\"不同宽度区间命中率:\")\n",
                "for k, v in metrics['不同宽度区间命中率'].items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "huawei_tabular",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
